{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leegonzales/LangChainExamples/blob/main/Public_Copy_Langchain_transcription_with_sources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V1 Query the YouTube video transcripts, returning timestamps as sources to legitimize the answers by [@m_morzywolek](https://twitter.com/m_morzywolek)\n",
        "\n",
        "## V2 with custom prompts and summaries included by [@leegonzales](https://twitter.com/leegonzales)\n"
      ],
      "metadata": {
        "id": "6WFk81JVP4Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First set runtime to GPU"
      ],
      "metadata": {
        "id": "jdwAawIyJ6nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC0p1VRjIlFE",
        "outputId": "8f6fbc66-43a0-4b3a-c322-6012e17c44ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install pytube # For audio downloading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/openai/whisper.git -q # Whisper from OpenAI transcription model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zAC6DJ5IwTk",
        "outputId": "7b24dda8-db00-4a7b-9b22-4f39d96d157a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper \n",
        "import pytube "
      ],
      "metadata": {
        "id": "8h_FeO8TI3Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.youtube.com/watch?v=8jEmIDwqnL4\"\n",
        "video = pytube.YouTube(url)"
      ],
      "metadata": {
        "id": "eOgbnvXkI50t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = video.streams.get_audio_only()\n",
        "audio.download(filename='tmp.mp3') # Downlods only audio from youtube video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ls2DYRxPJQmw",
        "outputId": "62d22b68-ad97-4726-caa8-48ea42530670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/tmp.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZ6sSu1Jgm-",
        "outputId": "5a4b5d18-6334-46cf-e554-633d22fdf287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:02<00:00, 191MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = model.transcribe('/content/tmp.mp3')"
      ],
      "metadata": {
        "id": "DMCQql4AJmaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = transcription['segments']"
      ],
      "metadata": {
        "id": "HS9GCRIQKogF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def store_segments(segments):\n",
        "  texts = []\n",
        "  start_times = []\n",
        "\n",
        "  for segment in segments:\n",
        "    text = segment['text']\n",
        "    start = segment['start']\n",
        "\n",
        "    # Convert the starting time to a datetime object\n",
        "    start_datetime = datetime.fromtimestamp(start)\n",
        "\n",
        "    # Format the starting time as a string in the format \"00:00:00\"\n",
        "    formatted_start_time = start_datetime.strftime('%H:%M:%S')\n",
        "\n",
        "    texts.append(\"\".join(text))\n",
        "    start_times.append(formatted_start_time)\n",
        "\n",
        "  return texts, start_times"
      ],
      "metadata": {
        "id": "lHVWts6YKuDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_segments(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4IaERsPKxKu",
        "outputId": "5252807b-9a28-4dec-d324-e047c4f303f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\" Hey everybody, Peter Zayn here. We've had a lot of questions come in about AI and what that means for the workforce moving forward.\",\n",
              "  ' What sort of activities should we expect to be replaced? What does this mean for economics and labor and politics?',\n",
              "  ' And are there any obvious winners either in terms of geography or sectors?',\n",
              "  ' What popular one that comes in is whether or not this is going to hit red states or blue states more, for example.',\n",
              "  \" The cop-out answer is we don't really know yet because we're dealing with technologies that have yet to be invented.\",\n",
              "  ' But there are a few general guidelines we have.',\n",
              "  \" First of all, it's not so much that jobs get created or destroyed. It's that they change.\",\n",
              "  \" And it's pretty common when you're dealing with an environment that has evolved because of technology, you know, jobs evolve too.\",\n",
              "  \" We've been talking about technology overwhelming the workforce really since the onset of the Industrial Revolution.\",\n",
              "  \" And it obviously generates changes. We don't all live on subsistence farms anymore.\",\n",
              "  ' The trick is whether or not the technology evolves faster than our political ability to adapt to the changing workforce conditions.',\n",
              "  \" And I would argue that at least at the moment we're nowhere near that.\",\n",
              "  \" I mean, yes, we're dealing with the Information Revolution and yes, there is the possibility that's going to replace a lot of jobs,\",\n",
              "  \" increase productivity to the point that a lot of people just don't have anything to do.\",\n",
              "  \" But we, that's all theoretical. Our experience in the last five years is if anything, it's going to be the opposite.\",\n",
              "  \" You see, the sort of things that IT evolutions do is it makes it, it's in the name, information, information tech.\",\n",
              "  ' It manipulates information at a faster rate. But that is not where the uneducated people in our society are.',\n",
              "  ' Most of the uneducated people in our society are in lower class, blue-collar jobs.',\n",
              "  \" That is not something that AI can help with at all. That's something that the advances we've seen in productivity are almost irrelevant.\",\n",
              "  ' AI instead is taking away those low to mid-skilled, white-collar jobs, which is not normally what we think of when we think about the sort of jobs that are going to be destroyed.',\n",
              "  \" So we've actually, in the last three years, seen the greatest increase in take-home pay for low-skilled, blue-collar workers in over a century.\",\n",
              "  ' And that has actually helped to give the case of the United States narrow economic inequality to a degree that we have not seen since before the World Wars.',\n",
              "  ' So if anything, the theory is proving itself wrong rather than right.',\n",
              "  \" However, if you're, say, a copy editor or a secretary, well, you might have some really big problems because AI already has been able to deal with those jobs in a more efficient manner.\",\n",
              "  \" You just don't need as many people. In fact, the blockchain, which is one of the things that underminds crypto, sorry, undergirds crypto, not undermines crypto,\",\n",
              "  ' is something that could be very transformative in things like healthcare.',\n",
              "  \" If you think about any doctor's office you've been in, there's that huge forest of staff in the back who are basically on the phone with the insurance agents every day all day.\",\n",
              "  ' Well, the whole idea of blockchain is that anyone who controls half of the pieces can grant others access.',\n",
              "  \" Well, in your healthcare records, that would be you. And if everything from that can be digitized, then that entire flood of low skilled white collar workers in the back of every doctor's office and hospitals simply goes away.\",\n",
              "  \" So it's probably not going to hit where we think it is. And it's probably not a red versus blue thing. And it's probably not a coastal versus interior thing.\",\n",
              "  \" It's mid levels of education versus the edges. If you're highly educated or low educated, you look fine from this.\",\n",
              "  \" Second, there's the issue of time. Now, obviously, these technologies continue moving, but there's two reasons to expect that we're going to have a lot more time to make this adaptation that I think a lot of people give a credit for.\",\n",
              "  ' Number one is as the baby boomers are retiring, which is happening right now, they are liquidating all of their investments and going into really boring stuff like T bills and cash.',\n",
              "  \" That's not what funds it startups. That's not even what funds the big IT companies in Silicon Valley. For that, you need venture capital, you need a high velocity of money retirees are no good for that.\",\n",
              "  \" And the whole world is aging very rapidly and baby boomers are not a phenomenon limited to the United States. So we're going to see the amount of capital just kind of sees up in the entire space.\",\n",
              "  ' At the same time, most of the world is running out of the 20 and the 30 somethings that are necessary to do the research and develop these technologies in the first place.',\n",
              "  \" So overall, we should expect the pace of technological evolution of the world to slow quite a bit in the two decades. Excuse me, in the two decades to come, compared to the two decades we've just completed.\",\n",
              "  \" Second, we're not close to a general AI breakthrough. Let me explain what I mean by that. Artificial intelligence kind of falls into two general buckets.\",\n",
              "  ' General AI is, you know, SkyNet, the idea that the machine can actually look at a situation thing come up with a potential solution and then act on it.',\n",
              "  \" Or no, we're close to that. I don't know anyone even Elon Musk thinks we're going to be there before 2050. And this is before you consider that the amount of capital and workers that are available to develop these sort of things isn't the process of drying up.\",\n",
              "  \" So probably we're looking at 2060, 2070 or beyond. We're just we're not even close. The other type of AI is applied AI or mission specific AI.\",\n",
              "  \" And it's not so much artificial intelligence in the way that we kind of have it in our heads, but it is machine learning. But it's really more like machine programming.\",\n",
              "  \" So you put in dozens, hundreds, thousands of if then statements into a program for it to execute. And as long as the conditions that are presented to the machine fall within the rubric of what you programmed, you're okay.\",\n",
              "  ' But if you see something even a little out of context, the whole thing tends to fall apart.',\n",
              "  \" So an example, let's say you're developing an AI driving program and you tell it what a stop sign looks like.\",\n",
              "  \" What if the stop sign has a bumper sticker on it or graffiti, or if it's on the side of a building as part of an ad applied AI can't recognize those other conditions.\",\n",
              "  \" And if you kind of widen your parameters to make it a rounding error, then it's going to make very real mistakes in the very real world that any four year old couldn't.\",\n",
              "  \" So if you need AI to do calculus, yes, they're light years ahead of what we as humans can do right now.\",\n",
              "  ' If you needed to make a decision based on a judgment call, they are still completely and utterly incompetent.',\n",
              "  \" All right, but let's assume, let's assume that some of this happens anyway.\",\n",
              "  \" And so we're going to have to deal with an AI system that is making decisions. What does that mean for the job industry?\",\n",
              "  \" So historically speaking, this is not the first time we've dealt with this issue. In fact, for those of you who remember your 1800s political economic theory good old Karl Marx,\",\n",
              "  ' his whole idea was that the future of the proletariat was to take over from the capitalists.',\n",
              "  ' And once the industrial plant was built, then you could get rid of the bourgeoisie and the proletariat could live and do very, very well for itself because the machines and the industrial plant would be there to provide for everyone.',\n",
              "  \" Well, folks, he was wrong then. He's still wrong now.\",\n",
              "  \" The universal basic income is the idea that we live in such a world of plenty that we don't need to work. But as we have seen in the next last three or five years, if anything, the opposite is true.\",\n",
              "  \" The productivity has stalled in part because of tech, but moreover, because we've discovered that as populations evolve in industrialization, we live longer, we have fewer kids,\",\n",
              "  \" and that means after we urbanize five, six, seven, eight decades after, we're actually running out of young people to do a lot of the lower skilled work.\",\n",
              "  ' So if anything, Marx was completely wrong because the part of the population that he thought that would benefit the most from industrialization is at the current moment actually not doing all that well, the middle class.',\n",
              "  \" It's the lower classes that are cleaning up right now. There are very, very few places in the United States at this point where if you were earning $15 an hour before COVID, you're still in that bracket today.\",\n",
              "  \" You've been able to leverage the fact that there's a sharp labor shortage to move up, and that means you have a vested interest in the system.\",\n",
              "  ' And it means if you decide to not work, there is no one who is willing to pay you to not work because there are jobs, jobs, jobs everywhere.',\n",
              "  ' So in conclusion, is AI real? Yes.',\n",
              "  \" But we've been thinking about it completely wrong, and most of the assessments that I have seen from almost everywhere are drawing the wrong conclusions when it comes to sociological outcomes.\",\n",
              "  \" It's going to be important. It's going to change who we are. It's going to change how we live and how we work. But the word here is change. It's not a revolution.\",\n",
              "  \" Alright, that's it from me. I'm going to go get a snow shuttle. Take care.\"],\n",
              " ['00:00:00',\n",
              "  '00:00:10',\n",
              "  '00:00:19',\n",
              "  '00:00:26',\n",
              "  '00:00:31',\n",
              "  '00:00:37',\n",
              "  '00:00:40',\n",
              "  '00:00:47',\n",
              "  '00:00:55',\n",
              "  '00:01:02',\n",
              "  '00:01:07',\n",
              "  '00:01:15',\n",
              "  '00:01:19',\n",
              "  '00:01:25',\n",
              "  '00:01:28',\n",
              "  '00:01:35',\n",
              "  '00:01:43',\n",
              "  '00:01:50',\n",
              "  '00:01:55',\n",
              "  '00:02:02',\n",
              "  '00:02:12',\n",
              "  '00:02:22',\n",
              "  '00:02:30',\n",
              "  '00:02:34',\n",
              "  '00:02:45',\n",
              "  '00:02:54',\n",
              "  '00:02:58',\n",
              "  '00:03:10',\n",
              "  '00:03:19',\n",
              "  '00:03:32',\n",
              "  '00:03:41',\n",
              "  '00:03:49',\n",
              "  '00:04:01',\n",
              "  '00:04:12',\n",
              "  '00:04:23',\n",
              "  '00:04:34',\n",
              "  '00:04:42',\n",
              "  '00:04:54',\n",
              "  '00:05:04',\n",
              "  '00:05:13',\n",
              "  '00:05:26',\n",
              "  '00:05:37',\n",
              "  '00:05:46',\n",
              "  '00:06:00',\n",
              "  '00:06:05',\n",
              "  '00:06:13',\n",
              "  '00:06:24',\n",
              "  '00:06:32',\n",
              "  '00:06:38',\n",
              "  '00:06:46',\n",
              "  '00:06:50',\n",
              "  '00:06:57',\n",
              "  '00:07:10',\n",
              "  '00:07:16',\n",
              "  '00:07:30',\n",
              "  '00:07:36',\n",
              "  '00:07:48',\n",
              "  '00:08:02',\n",
              "  '00:08:11',\n",
              "  '00:08:27',\n",
              "  '00:08:42',\n",
              "  '00:08:49',\n",
              "  '00:08:56',\n",
              "  '00:09:01',\n",
              "  '00:09:12',\n",
              "  '00:09:20'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, start_times = store_segments(res)"
      ],
      "metadata": {
        "id": "__-hrw_6LYsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "7auAzAfXL1V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d80d59d-f7d3-459e-c18f-1d09077f154b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.76-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Collecting SQLAlchemy<2,>=1\n",
            "  Downloading SQLAlchemy-1.4.46-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.25.1)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.4)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, SQLAlchemy, marshmallow-enum, dataclasses-json, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.0\n",
            "    Uninstalling SQLAlchemy-2.0.0:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.0\n",
            "Successfully installed SQLAlchemy-1.4.46 dataclasses-json-0.5.7 langchain-0.0.76 marshmallow-enum-1.5.1 mypy-extensions-0.4.3 typing-inspect-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "EMG0TDLoL5rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dd140e-0df1-4ec8-c5f5-dd635491d12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=c756543a37099ee7b696d98330f48db3f4ccab3e300ccfd10ee5e732a83c3a2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade faiss-gpu==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TNi-J7FMAlT",
        "outputId": "596e6377-cb02-40df-a737-06f977dba37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu==1.7.1\n",
            "  Downloading faiss_gpu-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import faiss"
      ],
      "metadata": {
        "id": "sJvI6zAcLpDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "OPENAI_API_KEY = getpass('Enter your OpenAI key: ')"
      ],
      "metadata": {
        "id": "eU40XsWdMHJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d13417-acd8-4677-828b-75d9f3d94377"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "l6iQ3mAaGLNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1500, separator=\"\\n\")\n",
        "docs = []\n",
        "metadatas = []\n",
        "for i, d in enumerate(texts):\n",
        "    splits = text_splitter.split_text(d)\n",
        "    docs.extend(splits)\n",
        "    metadatas.extend([{\"source\": start_times[i]}] * len(splits))\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "6ZylCKSqMLm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = FAISS.from_texts(docs, embeddings, metadatas=metadatas)\n",
        "faiss.write_index(store.index, \"docs.index\")"
      ],
      "metadata": {
        "id": "VScsZ_MzMRuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = VectorDBQAWithSourcesChain.from_llm(llm=OpenAI(temperature=0), vectorstore=store)"
      ],
      "metadata": {
        "id": "tk-fzMBgMt9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": \"For each major point Peter raises, where is he wrong?\"})"
      ],
      "metadata": {
        "id": "8JUgPLpnNOvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f89222-e869-49e9-9f85-9987ddf3a006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Answer: {result['answer']}  Sources: {result['sources']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4gg4C1NX_h",
        "outputId": "154a0ebc-b685-4bbd-9522-d3e0b7e59d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  I don't know.\n",
            "  Sources: 00:07:30, 00:02:30, 00:06:00, 00:09:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "summaryDoc = [Document(page_content=t) for t in texts[:3]]"
      ],
      "metadata": {
        "id": "TBjmFfTiCgkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "prompt_template = \"\"\"Write a complete and thorough synopsis of the following, include a bulleted list of his points:\n",
        "\n",
        "\n",
        "{text}\n",
        "\n",
        "Output using the following format\n",
        "SYNOPSIS:\n",
        "\n",
        "KEY POINTS:\"\"\""
      ],
      "metadata": {
        "id": "rh_JBLQ0DY_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "chain = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\", prompt=PROMPT)\n",
        "chain.run(summaryDoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "UbgUwTZ-FAbI",
        "outputId": "316e68cc-593f-470a-eb05-d92e6a1f55c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n- Peter Zayn is discussing the implications of Artificial Intelligence (AI) on the workforce.\\n- He is exploring what activities will be replaced by AI, and what this means for economics, labor, and politics.\\n- He is also considering which geographical areas and sectors will benefit from the introduction of AI.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "chain = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "chain.run(summaryDoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "w0hmo67X-UR6",
        "outputId": "6fda932e-d9d6-498e-b081-8149304f6a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Peter Zayn is discussing the implications of AI on the workforce, economics, labor, and politics. He is asking what activities will be replaced, and who will benefit from the changes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}